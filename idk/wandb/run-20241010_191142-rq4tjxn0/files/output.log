Traceback (most recent call last):
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\main.py", line 80, in <module>
    dataset.sample(model, device_type, starting_text, 100)
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\data.py", line 138, in sample
    out, new = model.generate(image, starting_text, num_tokens)
  File "C:\Users\Spher\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\model.py", line 23, in generate
    x, new = self.language_model.generate(image_embed, starting_text, max_new_tokens, temperature, do_sample, top_k)
  File "C:\Users\Spher\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\text\gpt2.py", line 67, in generate
    logits, _ = self(image_embed, idx_cond)
  File "C:\Users\Spher\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Spher\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\text\gpt2.py", line 44, in forward
    x = self.drop(img_embeds + emb + pos)
RuntimeError: The size of tensor a (484) must match the size of tensor b (512) at non-singleton dimension 1
Traceback (most recent call last):
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\main.py", line 80, in <module>
    dataset.sample(model, device_type, starting_text, 100)
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\data.py", line 138, in sample
    out, new = model.generate(image, starting_text, num_tokens)
  File "C:\Users\Spher\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\model.py", line 23, in generate
    x, new = self.language_model.generate(image_embed, starting_text, max_new_tokens, temperature, do_sample, top_k)
  File "C:\Users\Spher\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\text\gpt2.py", line 67, in generate
    logits, _ = self(image_embed, idx_cond)
  File "C:\Users\Spher\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Spher\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Spher\OneDrive\Desktop\CS\AI\Image_Caption\image-captioning\text\gpt2.py", line 44, in forward
    x = self.drop(img_embeds + emb + pos)
RuntimeError: The size of tensor a (484) must match the size of tensor b (512) at non-singleton dimension 1